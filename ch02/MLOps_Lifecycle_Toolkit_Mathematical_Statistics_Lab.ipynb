{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## MLOps Lifecycle Toolkit Chapter 2 Lab: Mathematical Statistics Fundamentals\n",
        "* [Probability Distributions in Python](#probability-distributions)\n",
        "* [Creating Your Own Mathematical Functions in Python](#mathematical-functions)\n",
        "* [Coin Toss Experiment](#coin-toss-experiment)\n",
        "* [Computing the Characteristic Function of a Discrete Probability Distribution In Python](#installing-packages)\n",
        "* [Recovering the Probability Distribution from a Characteristic Function in Python](#bayesian-example)\n"
      ],
      "metadata": {
        "id": "740YAk0HwbfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import some mathematical packages "
      ],
      "metadata": {
        "id": "ZAHRKBF43gx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import math"
      ],
      "metadata": {
        "id": "dDj8oMCsOTya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the characteristic function of a normal distribution ~ N(5, 1)  with mean 5 and unit standard deviation. This is a complex valued function. Characteristic functions are a fundamental tool in mathematical statistics and even used in the proof of the Central Limit Theorem.\n"
      ],
      "metadata": {
        "id": "l85w6TIA3jap"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GszsB5alpx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68442f1d-0e31-4fd7-9fcc-dfc9849a3769"
      },
      "source": [
        "sigma = 1\n",
        "mu = 5\n",
        "N = 100\n",
        "\n",
        "\n",
        "def char(t):\n",
        " \"\"\"\n",
        " Estimate of characteristic function for normally distributed data set\n",
        " \"\"\"\n",
        " val = np.exp((1j)*t*mu-(1/2)*sigma**2 * t**2)\n",
        " return val\n",
        "\n",
        "\n",
        "char(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.693869103004312e-06-4.932290693320294e-07j)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note, this is actually a discrete-time Fourier transform. The details of this calculation are standard in many mathematical statistics textbooks but take our word for it."
      ],
      "metadata": {
        "id": "Imxkx24G-cJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to create a function to estimates the probability mass function for a discrete training set X_train. Here X_train will be a list of numbers representing the result of a coin toss."
      ],
      "metadata": {
        "id": "ZUUfzuu117bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def estimate_pmf(X_train):\n",
        " \"\"\"\n",
        " Estimate the probability mass function for training data X\n",
        " \"\"\"\n",
        " _, freq = np.unique(X_train, return_counts=True)\n",
        " estimate = freq / X_train.size\n",
        " return estimate\n"
      ],
      "metadata": {
        "id": "u6G4yROaOiR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coin Toss Simulation \n",
        "\n",
        "Let's generate our training set. We simulate N = 10,000 random flips of a fair coin. We encode flip as 'H' for heads and 'T' for tails and store the result in a list called vector."
      ],
      "metadata": {
        "id": "Cn5ITth92Cqv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiMwMIJsmXle"
      },
      "source": [
        "#set random seed for reproducibility\n",
        "random.seed(123)\n",
        "\n",
        "#simulate 10,000 trials\n",
        "N = 10000\n",
        "\n",
        "def toss_simulation():\n",
        " \"\"\"\n",
        " Simulate coin toss for a fair coin\n",
        " \"\"\"\n",
        " return random.choice(['H', 'T'])\n",
        "\n",
        "\n",
        "# training data size = N\n",
        "X_train = np.array([toss_simulation() for _ in np.arange(N)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need to create the inverse function to compute the characteristic function. In Python, a function can return another function!"
      ],
      "metadata": {
        "id": "AUlYZeaq2RcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_char(vector):\n",
        "  \"\"\"\n",
        "  This returns the characteristic\n",
        "  function of a pmf represented\n",
        "  as a vector.\n",
        "  \"\"\"\n",
        "  def char(w):\n",
        "      \"\"\"\n",
        "      Compute characteristic function at poitn x given PMF\n",
        "      \"\"\"\n",
        "      pmf = estimate_pmf(vector)\n",
        "      l = len(pmf)\n",
        "      weights = pmf[:l]\n",
        "      phi = [np.exp((1j)*(math.pi)*w*k) for k in range(l)]\n",
        "      return np.dot(phi, pmf[:l])\n",
        "  return char\n",
        "\n",
        "char = compute_char(X_train)"
      ],
      "metadata": {
        "id": "pjnfSBtaOSxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you use it to recover the original Bernoulli proability distribution for our coin toss from the characteristic function? Yes, we need to use the inverse Fourier transform.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wm5szcQM2Xb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def proba(x, char, N):\n",
        " \"\"\"\n",
        " x (float): value of random variable rv in range 0, 1,2, ... N-1\n",
        " char (func): estimation of characteristic function  for random variable\n",
        " N (int): total number of discrete outcomes in probability mass function\n",
        " returns: re-constructed probability of rv at x\n",
        " \"\"\"\n",
        " if x < N:\n",
        "   probability = 1/N * np.sum(\n",
        "      np.array(\n",
        "      [char(2*n*math.pi/N) * np.exp((-1j)*2*math.pi*x*n/N) for n in np.arange(N)]\n",
        "      )\n",
        "   )\n",
        "   # probability should be a real number between 0 and 1\n",
        "   if probability.real > 1:\n",
        "     raise ValueError(\"Probability estimate out of bounds.\")\n",
        "   return probability.real\n",
        " else:\n",
        "   raise ValueError(\"Point x is not in support of random variable.\")"
      ],
      "metadata": {
        "id": "RekhYghfRBzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's print out the probability of success and failure for our coin toss based on the recovered probability distribution to see if our experiment worked.\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "h4TiYf7yA5qA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_outcomes = 2 # heads or tails\n",
        "\n",
        "p , q = [proba(x, char, 2) for x in range(2) ] \n",
        "\n",
        "print(f\"The probability of heads is {p} and the probability of tails is {q}\")"
      ],
      "metadata": {
        "id": "hplzjnTdxUYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48eef85f-afbe-4516-d45b-c47ee45daf49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of heads is 0.5236627196400556 and the probability of tails is 0.4763372803599444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok it recovered probability of heads as 0.52 which is pretty close to 0.5. Our experiment worked!"
      ],
      "metadata": {
        "id": "uxl01DK04uYZ"
      }
    }
  ]
}